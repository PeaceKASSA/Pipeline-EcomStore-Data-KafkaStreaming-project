# Real-Time E-Commerce Data Engineering Project using Apache Kafka, Python & Snowflake

---

## ðŸ“Œ Project Overview

This project simulates a real-time e-commerce event pipeline, where user activity data is continuously ingested, validated, and made analytics-ready; A production-style, time data engineering project using Apache Kafka, Python, and Snowflake.

This project demonstrates how Kafka is actually used in real systems â€” including message keys, partitioning, streaming data validation, offset management, and warehouse-first analytics â€” not just basic producers and consumers.

It follows a Medallion Architecture (Bronze â†’ Silver â†’ Gold) approach, where:
Kafka handles real-time ingestion and data quality
Python handles stream processing
Snowflake handles analytics and business logic using SQL

## âš¡ Stack Used
- **Python**
- **ApacheKafka** 
- **Docker** 
- **Kafka producers and consumers**
- **Real-time stream processing**
- **Snowflake**

---

## âœ… Key Takeaways
The Learning Goals of this hands-on project:

â€¢ Generate continuous real-time events using Python
â€¢ Design Kafka topics with message keys and partitions
â€¢ Understand how Kafka partitioning and ordering actually work
â€¢ Build a Bronze â†’ Silver streaming pipeline
â€¢ Clean and validate streaming data using Python consumers
â€¢ Manage Kafka offsets safely (no data loss)
â€¢ Load real-time data into Snowflake efficiently
â€¢ Separate streaming logic from analytics logic
â€¢ Implement Gold-layer transformations using Snowflake SQL

**Author:** *Peace KASSA*  